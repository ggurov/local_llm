version: "3.9"

services:
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - HF_HOME=${HF_HOME}
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES_LLM}
    volumes:
      - ./models:/root/.cache/huggingface
    command: >
      --model ${MODEL_ID}
      --max-model-len ${MAX_MODEL_LEN}
      --gpu-memory-utilization ${GPU_MEM_UTIL}
      --served-model-name ${MODEL_ID}
      --host 0.0.0.0
      --port 8000
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  embeddings:
    image: python:3.11-slim
    container_name: tei
    restart: unless-stopped
    ports:
      - "8081:8081"
    environment:
      - MODEL_ID=${EMBEDDINGS_MODEL}
    volumes:
      - ./embeddings_service.py:/app/embeddings_service.py
    command: >
      bash -c "
      pip install sentence-transformers fastapi uvicorn &&
      python /app/embeddings_service.py
      "

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334

  langfuse:
    image: langfuse/langfuse:latest
    container_name: langfuse
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}
      - DATABASE_URL=file:./data/langfuse.db
      - LANGFUSE_ENCRYPTION_KEY=devkey_change_in_production
    volumes:
      - ./data/langfuse:/app/data

  orchestrator:
    build: ./orchestrator
    container_name: orchestrator
    depends_on:
      - vllm
      - embeddings
      - qdrant
    ports:
      - "${ORCHESTRATOR_PORT}:8001"
    environment:
      - OPENAI_COMPAT_URL=http://vllm:8000/v1
      - EMBED_URL=http://embeddings:8081
      - QDRANT_URL=http://qdrant:6333
      - LANGFUSE_HOST=http://langfuse:3000
      - LANGFUSE_PUBLIC_KEY=dev_public_key
      - LANGFUSE_SECRET_KEY=dev_secret_key
      - LOG_LEVEL=${LOG_LEVEL}
    volumes:
      - ./orchestrator:/app
      - ./tools:/app/tools
    command: ["python", "-m", "app.main"]

networks:
  default:
    name: local-llm-network